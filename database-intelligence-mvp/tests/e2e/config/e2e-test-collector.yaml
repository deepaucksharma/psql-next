extensions:
  health_check:
    endpoint: 0.0.0.0:13133
    
  zpages:
    endpoint: 0.0.0.0:55679


receivers:
  postgresql:
    endpoint: ${env:POSTGRES_HOST:-localhost}:${env:POSTGRES_PORT:-5432}
    username: ${env:POSTGRES_USER:-postgres}
    password: ${env:POSTGRES_PASSWORD:-postgres}
    databases:
      - ${env:POSTGRES_DB:-postgres}
    collection_interval: 30s
    tls:
      insecure: true

  mysql:
    endpoint: ${env:MYSQL_HOST:-localhost}:${env:MYSQL_PORT:-3306}
    username: ${env:MYSQL_USER:-root}
    password: ${env:MYSQL_PASSWORD:-mysql}
    database: ${env:MYSQL_DB:-mysql}
    collection_interval: 30s

  # SQL query receiver for test query logs
  sqlquery/postgresql:
    driver: postgres
    datasource: "host=${env:POSTGRES_HOST:-localhost} port=${env:POSTGRES_PORT:-5432} user=${env:POSTGRES_USER:-postgres} password=${env:POSTGRES_PASSWORD:-postgres} dbname=${env:POSTGRES_DB:-postgres} sslmode=disable"
    queries:
      - sql: |
          SELECT
            'e2e_test_' || generate_series as query_id,
            'SELECT * FROM test_table_' || generate_series as query_text,
            (50 + random() * 100)::numeric(10,2) as avg_duration_ms,
            (10 + random() * 90)::int as execution_count,
            ((50 + random() * 100) * (10 + random() * 90))::numeric(10,2) as total_duration_ms,
            current_database() as database_name
          FROM generate_series(1, 5)
        logs:
          - body_column: query_text
            attributes:
              query_id: query_id
              avg_duration_ms: avg_duration_ms
              execution_count: execution_count
              total_duration_ms: total_duration_ms
              database_name: database_name
    collection_interval: 60s

  sqlquery/mysql:
    driver: mysql
    datasource: "${env:MYSQL_USER:-root}:${env:MYSQL_PASSWORD:-mysql}@tcp(${env:MYSQL_HOST:-localhost}:${env:MYSQL_PORT:-3306})/${env:MYSQL_DB:-mysql}"
    queries:
      - sql: |
          SELECT 
            'mysql_e2e_test_1' as query_id,
            'SELECT * FROM users WHERE active = 1' as query_text,
            75.5 as avg_duration_ms,
            50 as execution_count,
            3775.0 as total_duration_ms,
            DATABASE() as database_name
        logs:
          - body_column: query_text
            attributes:
              query_id: query_id
              avg_duration_ms: avg_duration_ms
              execution_count: execution_count
              total_duration_ms: total_duration_ms
              database_name: database_name
    collection_interval: 60s

processors:
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128

  # Add resource attributes
  resource:
    attributes:
      - key: collector.name
        value: otelcol
        action: upsert
      - key: test.environment
        value: e2e
        action: upsert
      - key: test.run_id
        value: ${env:TEST_RUN_ID:-default}
        action: upsert

  # Transform processors for data normalization
  transform/metrics:
    error_mode: ignore
    metric_statements:
      - context: metric
        statements:
          - set(unit, "1") where unit == ""

  transform/logs:
    error_mode: ignore
    log_statements:
      - context: log
        statements:
          - set(attributes["avg_duration_ms"], Double(attributes["avg_duration_ms"])) where attributes["avg_duration_ms"] != nil
          - set(attributes["execution_count"], Int(attributes["execution_count"])) where attributes["execution_count"] != nil
          - set(attributes["total_duration_ms"], Double(attributes["total_duration_ms"])) where attributes["total_duration_ms"] != nil

  batch:
    timeout: 10s
    send_batch_size: 100

  attributes:
    actions:
      - key: test.environment
        value: e2e
        action: insert

exporters:
  otlp/newrelic:
    endpoint: ${env:NEW_RELIC_OTLP_ENDPOINT:-otlp.nr-data.net:4317}
    headers:
      api-key: ${env:NEW_RELIC_LICENSE_KEY}
    compression: gzip
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 1000

  # Debug exporter for troubleshooting
  debug:
    verbosity: detailed
    sampling_initial: 10
    sampling_thereafter: 100

  # File exporter for validation
  file:
    path: /tmp/e2e-metrics.json
    format: json

service:
  pipelines:
    metrics/postgres:
      receivers: [postgresql]
      processors: [memory_limiter, resource, transform/metrics, batch]
      exporters: [otlp/newrelic, file, debug]

    metrics/mysql:
      receivers: [mysql]
      processors: [memory_limiter, resource, transform/metrics, batch]
      exporters: [otlp/newrelic, file, debug]

    logs/queries:
      receivers: [sqlquery/postgresql, sqlquery/mysql]
      processors: [memory_limiter, resource, transform/logs, attributes, batch]
      exporters: [otlp/newrelic, file, debug]

  extensions: [health_check, zpages]
  
  telemetry:
    logs:
      level: info
      output_paths: ["/tmp/e2e-collector.log"]
    metrics:
      level: detailed
      address: 0.0.0.0:8888