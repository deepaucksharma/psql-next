
//go:build e2e

package e2e

import (
	"bytes"
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"net/http"
	"os"
	"path/filepath"
	"testing"
	"time"

	_ "github.com/lib/pq"
	"github.com/stretchr/testify/suite"
	"github.com/testcontainers/testcontainers-go"
	"github.com/testcontainers/testcontainers-go/modules/postgres"
	"github.com/testcontainers/testcontainers-go/wait"
	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/confmap"
	"go.opentelemetry.io/collector/otelcol"
	"go.opentelemetry.io/collector/extension"
	"go.opentelemetry.io/collector/processor"
	"go.opentelemetry.io/collector/receiver"
	"go.opentelemetry.io/collector/exporter"
	"go.opentelemetry.io/collector/connector"
	"go.uber.org/zap"
	"go.uber.org/zap/zaptest"
)

// E2ETestSuite defines the structure for our end-to-end test suite.
// It holds the state for all necessary components like the database container,
// the collector, and database connections.
type E2ETestSuite struct {
	suite.Suite
	logger      *zap.Logger
	pgContainer *postgres.PostgresContainer
	pgDB        *sql.DB
	collector   *otelcol.Collector
}

// SetupSuite runs once before all tests in the suite.
// It sets up the entire test environment, including the PostgreSQL database container.
func (s *E2ETestSuite) SetupSuite() {
	s.logger = zaptest.NewLogger(s.T())
	ctx := context.Background()

	// Get the project root directory to locate the seed script
	// This is a simplified approach; a more robust solution might use build tags or environment variables.
	projectRoot, err := os.Getwd()
	s.Require().NoError(err, "Failed to get current working directory")
	projectRoot = filepath.Dir(filepath.Dir(projectRoot)) // Navigate up to the project root from /tests/e2e

	seedScriptPath := filepath.Join(projectRoot, "tests", "e2e", "sql", "seed.sql")
	s.logger.Info("Using seed script", zap.String("path", seedScriptPath))

	// Start PostgreSQL container using Testcontainers
	s.logger.Info("Starting PostgreSQL container...")
	s.pgContainer, err = postgres.RunContainer(ctx,
		testcontainers.WithImage("postgres:15-alpine"),
		postgres.WithDatabase("testdb"),
		postgres.WithUsername("testuser"),
		postgres.WithPassword("testpass"),
		postgres.WithInitScripts(seedScriptPath),
		testcontainers.WithWaitStrategy(
			wait.ForLog("database system is ready to accept connections").
				WithOccurrence(2).
				WithStartupTimeout(60*time.Second),
		),
	)
	s.Require().NoError(err, "Failed to start PostgreSQL container")
	s.logger.Info("PostgreSQL container started successfully")

	// Establish database connection
	connStr, err := s.pgContainer.ConnectionString(ctx, "sslmode=disable")
	s.Require().NoError(err, "Failed to get connection string")

	s.pgDB, err = sql.Open("postgres", connStr)
	s.Require().NoError(err, "Failed to connect to PostgreSQL")

	// Ping the database to ensure connectivity
	err = s.pgDB.PingContext(ctx)
	s.Require().NoError(err, "Failed to ping PostgreSQL database")
	s.logger.Info("Successfully connected to the test database")
}

// TearDownSuite runs once after all tests in the suite are complete.
// It cleans up the environment by stopping the database container and the collector.
func (s *E2ETestSuite) TearDownSuite() {
	s.logger.Info("Tearing down test suite...")

	// Shutdown collector if it's running
	if s.collector != nil {
		s.collector.Shutdown()
	}

	// Close database connection
	if s.pgDB != nil {
		s.pgDB.Close()
	}

	// Terminate the PostgreSQL container
	if s.pgContainer != nil {
		err := s.pgContainer.Terminate(context.Background())
		s.NoError(err, "Failed to terminate PostgreSQL container")
		s.logger.Info("PostgreSQL container terminated")
	}
}

// startCollector is a helper function to start the OpenTelemetry collector for a test.
func (s *E2ETestSuite) startCollector(cfg *confmap.Conf) {
	settings := otelcol.CollectorSettings{
		BuildInfo: component.BuildInfo{
			Command: "otelcol-e2e-test",
			Version: "1.0.0",
		},
		Factories: func() (otelcol.Factories, error) {
			// Use basic factories for test
			factories := otelcol.Factories{}
			factories.Extensions = make(map[component.Type]extension.Factory)
			factories.Receivers = make(map[component.Type]receiver.Factory)
			factories.Processors = make(map[component.Type]processor.Factory)
			factories.Exporters = make(map[component.Type]exporter.Factory)
			factories.Connectors = make(map[component.Type]connector.Factory)
			return factories, nil
		},
	}

	var err error
	s.collector, err = otelcol.NewCollector(settings)
	s.Require().NoError(err, "Failed to create collector")

	go func() {
		err := s.collector.Run(context.Background())
		s.Require().NoError(err, "Collector run returned an error")
	}()

	// Wait for the collector to start up
	for state := range s.collector.GetStateChannel() {
		if state == otelcol.StateRunning {
			break
		}
	}
	s.logger.Info("Collector started successfully")
}

// TestDatabaseConnection is a simple test to verify the database connection.
func (s *E2ETestSuite) TestDatabaseConnection() {
	s.logger.Info("Running TestDatabaseConnection")
	err := s.pgDB.PingContext(context.Background())
	s.NoError(err, "Database should be pingable")

	var version string
	err = s.pgDB.QueryRow("SELECT version()").Scan(&version)
	s.NoError(err, "Should be able to query database version")
	s.logger.Info("PostgreSQL Version", zap.String("version", version))
	s.NotEmpty(version, "Version string should not be empty")
}

// TestPipelineIntegrity verifies the data pipeline to New Relic.
func (s *E2ETestSuite) TestPipelineIntegrity() {
	s.logger.Info("Running TestPipelineIntegrity")

	// Load the golden test configuration
	cfgPath := filepath.Join(".", "collector-e2e-test.yaml")
	cfg, err := confmap.NewResolver(confmap.ResolverSettings{URIs: []string{cfgPath}})
	s.Require().NoError(err, "Failed to load golden config")

	// Start the collector
	s.startCollector(cfg)

	// Generate some workload to produce metrics
	_, err = s.pgDB.Exec("SELECT * FROM users WHERE id = 1")
	s.Require().NoError(err)

	// Allow time for data to be collected and exported
	s.logger.Info("Waiting for data to be exported to New Relic...")
	time.Sleep(30 * time.Second) // Adjust as needed

	// --- Verification Step: Check for Silent Failures ---
	s.Run("CheckNrIntegrationErrors", func() {
		query := fmt.Sprintf(`{
			actor {
				account(id: %s) {
					nrql(query: "SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' AND message LIKE '%%database%%' SINCE 30 minutes ago") {
						results
					}
				}
			}
		}`, os.Getenv("NEW_RELIC_ACCOUNT_ID"))

		count := s.executeNRQL(query)
		s.Equal(0.0, count, "Should have no integration errors")
	})

	// --- Verification Step: Check for Data Freshness ---
	s.Run("CheckDataFreshness", func() {
		query := fmt.Sprintf(`{
			actor {
				account(id: %s) {
					nrql(query: "SELECT latest(timestamp) FROM Metric WHERE collector.name = 'database-intelligence' SINCE 10 minutes ago") {
						results
					}
				}
			}
		}`, os.Getenv("NEW_RELIC_ACCOUNT_ID"))

		// This is a placeholder for the actual check. A real implementation would parse the result.
		// For now, we just execute the query.
		_ = s.executeNRQL(query)
		s.logger.Info("Data freshness check executed. Manual verification of the result is needed.")
	})

	// --- Verification Step: Check Collector Health Telemetry ---
	s.Run("CheckCollectorHealthTelemetry", func() {
		query := fmt.Sprintf(`{
			actor {
				account(id: %s) {
					nrql(query: "SELECT average(otelcol_process_memory_rss) FROM Metric SINCE 10 minutes ago") {
						results
					}
				}
			}
		}`, os.Getenv("NEW_RELIC_ACCOUNT_ID"))

		// A real test would assert a non-zero value.
		_ = s.executeNRQL(query)
		s.logger.Info("Collector health telemetry check executed.")
	})
}

// TestDataAccuracy validates that the data in New Relic matches the source database.
func (s *E2ETestSuite) TestDataAccuracy() {
	s.logger.Info("Running TestDataAccuracy")

	// 1. Generate a specific, known workload
	var totalCalls int
	for i := 0; i < 15; i++ {
		_, err := s.pgDB.Exec("SELECT * FROM users WHERE username = 'testuser1'")
		s.Require().NoError(err)
		totalCalls++
	}

	// Allow time for collection
	time.Sleep(20 * time.Second)

	// 2. Get ground truth from the database
	var dbCalls int
	err := s.pgDB.QueryRow("SELECT calls FROM pg_stat_statements WHERE query LIKE 'SELECT * FROM users WHERE username = %'").Scan(&dbCalls)
	s.Require().NoError(err)

	// 3. Get the metric from New Relic
	query := fmt.Sprintf(`{
		actor {
			account(id: %s) {
				nrql(query: "SELECT latest(db.query.calls) FROM Metric WHERE db.query.text LIKE 'SELECT * FROM users WHERE username = %%' SINCE 5 minutes ago") {
					results
				}
			}
		}
	}`, os.Getenv("NEW_RELIC_ACCOUNT_ID"))

	// This is a placeholder for the actual check. A real implementation would parse the result.
	_ = s.executeNRQL(query)
	s.logger.Info("Ground truth comparison check executed. Manual verification of the result is needed.")
}

// TestOHISemanticParity verifies that OTEL metrics can provide the same insights as OHI events.
func (s *E2ETestSuite) TestOHISemanticParity() {
	s.logger.Info("Running TestOHISemanticParity")

	// OHI Use Case: Find the top 5 slowest queries.
	// Verification: Run a workload, then query New Relic for the top 5 queries by mean_duration.
	_, err := s.pgDB.Exec("SELECT pg_sleep(0.5) FROM generate_series(1,3)") // Generate a slow query
	s.Require().NoError(err)

	time.Sleep(20 * time.Second) // Allow for collection

	query := fmt.Sprintf(`{
		actor {
			account(id: %s) {
				nrql(query: "SELECT average(db.query.mean_duration) FROM Metric WHERE db.query.mean_duration IS NOT NULL FACET db.query.text SINCE 5 minutes ago LIMIT 5") {
					results
				}
			}
		}
	}`, os.Getenv("NEW_RELIC_ACCOUNT_ID"))

	_ = s.executeNRQL(query)
	s.logger.Info("OHI semantic parity check for slowest queries executed.")
}

// TestDimensionalCorrectness verifies that metrics have the correct dimensions.
func (s *E2ETestSuite) TestDimensionalCorrectness() {
	s.logger.Info("Running TestDimensionalCorrectness")

	query := fmt.Sprintf(`{
		actor {
			account(id: %s) {
				nrql(query: "SELECT uniques(db.name) FROM Metric WHERE metricName = 'postgresql.connections.active' SINCE 10 minutes ago") {
					results
				}
			}
		}
	}`, os.Getenv("NEW_RELIC_ACCOUNT_ID"))

	_ = s.executeNRQL(query)
	s.logger.Info("Dimensional correctness check for db.name executed.")
}

// TestEntitySynthesis verifies that New Relic entities are created correctly.
func (s *E2ETestSuite) TestEntitySynthesis() {
	s.logger.Info("Running TestEntitySynthesis")

	// This test requires NerdGraph API to verify entity creation.
	// For now, we will just log the intent.
	s.logger.Info("Entity Synthesis test requires manual verification in the New Relic UI or via NerdGraph API.")
	s.logger.Info("Check for a 'DATABASE' entity named 'testdb' linked to the test host.")
}

// TestAdvancedProcessors validates the custom processors.
func (s *E2ETestSuite) TestAdvancedProcessors() {
	s.logger.Info("Running TestAdvancedProcessors")

	// --- Adaptive Sampler Test ---
	s.Run("AdaptiveSampler", func() {
		// Generate a mix of fast and slow queries
		_, err := s.pgDB.Exec("SELECT pg_sleep(0.01) FROM generate_series(1,10)")
		s.Require().NoError(err)
		_, err = s.pgDB.Exec("SELECT pg_sleep(0.2) FROM generate_series(1,2)")
		s.Require().NoError(err)

		time.Sleep(20 * time.Second)

		// Placeholder for NRQL query to check sampling rates
		s.logger.Info("Adaptive Sampler test executed. Manual verification of sampling rates in New Relic is needed.")
	})

	// --- Circuit Breaker Test ---
	s.Run("CircuitBreaker", func() {
		// To test this, we would need to simulate database unavailability.
		// For now, we log the intent.
		s.logger.Info("Circuit Breaker test requires manual intervention (e.g., stopping the DB container) to verify.")
	})
}

// executeNRQL is a helper to run a NRQL query against the NerdGraph API.
func (s *E2ETestSuite) executeNRQL(query string) float64 {
	apiKey := os.Getenv("NEW_RELIC_LICENSE_KEY")
	s.Require().NotEmpty(apiKey, "NEW_RELIC_LICENSE_KEY must be set")

	reqBody := map[string]string{"query": query}
	jsonBody, err := json.Marshal(reqBody)
	s.Require().NoError(err)

	req, err := http.NewRequest("POST", "https://api.newrelic.com/graphql", bytes.NewBuffer(jsonBody))
	s.Require().NoError(err)

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("API-Key", apiKey)

	client := &http.Client{Timeout: 15 * time.Second}
	resp, err := client.Do(req)
	s.Require().NoError(err)
	defer resp.Body.Close()

	s.Equal(http.StatusOK, resp.StatusCode, "NerdGraph API request should be successful")

	var result struct {
		Data struct {
			Actor struct {
				Account struct {
					Nrql struct {
						Results []map[string]interface{} `json:"results"`
					} `json:"nrql"`
				} `json:"account"`
			} `json:"actor"`
		} `json:"data"`
	}

	err = json.NewDecoder(resp.Body).Decode(&result)
	s.Require().NoError(err)

	if len(result.Data.Actor.Account.Nrql.Results) > 0 {
		if count, ok := result.Data.Actor.Account.Nrql.Results[0]["count(*)"].(float64); ok {
			return count
		}
	}
	return -1 // Indicate an issue with parsing the result
}

// TestMain runs the entire test suite.
func TestE2EMain(t *testing.T) {
	suite.Run(t, new(E2ETestSuite))
}
