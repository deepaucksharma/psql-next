# Enterprise-Grade Core Metrics Collector Configuration
# Reference implementation with circuit breakers, persistent queues, and multi-pipeline architecture

receivers:
  # Primary MySQL receiver with optimized settings
  mysql:
    endpoint: ${env:MYSQL_ENDPOINT}
    username: ${env:MYSQL_USER}
    password: ${env:MYSQL_PASSWORD}
    collection_interval: ${env:COLLECTION_INTERVAL:-10s}
    transport: tcp
    initial_delay: 5s
    timeout: 30s

  # Federation receiver for cross-module metrics
  prometheus/federation:
    config:
      scrape_configs:
        - job_name: 'core-metrics-federation'
          scrape_interval: 30s
          static_configs:
            - targets: ['${env:FEDERATION_TARGETS:-localhost:8082,localhost:8083}']
          metrics_path: /metrics

processors:
  # Enterprise memory management with circuit breaker integration
  memory_limiter:
    check_interval: 5s
    limit_percentage: ${env:MEMORY_LIMIT_PERCENT:-80}
    spike_limit_percentage: ${env:MEMORY_SPIKE_PERCENT:-30}

  # Optimized batching for different pipeline priorities
  batch/standard:
    timeout: ${env:BATCH_TIMEOUT_STANDARD:-10s}
    send_batch_size: ${env:BATCH_SIZE_STANDARD:-1000}
    send_batch_max_size: 1500

  batch/critical:
    timeout: ${env:BATCH_TIMEOUT_CRITICAL:-2s}
    send_batch_size: ${env:BATCH_SIZE_CRITICAL:-100}
    send_batch_max_size: 200

  # Core metrics specific attributes
  attributes/core_metrics:
    actions:
      - key: module
        value: core-metrics
        action: insert
      - key: mysql.endpoint
        value: ${env:MYSQL_ENDPOINT}
        action: insert
      - key: cluster.name
        value: ${env:CLUSTER_NAME}
        action: insert
      - key: environment
        value: ${env:ENVIRONMENT}
        action: insert
      - key: tier
        value: foundation
        action: insert

  # Standardized resource attributes
  resource/standard:
    attributes:
      - key: service.name
        value: core-metrics
        action: upsert
      - key: service.version
        value: ${env:SERVICE_VERSION:-2.0.0}
        action: upsert
      - key: service.instance.id
        value: ${env:HOSTNAME}-core-metrics
        action: upsert

  # New Relic specific attributes
  attributes/newrelic:
    actions:
      - key: newrelic.source
        value: opentelemetry
        action: insert
      - key: instrumentation.name
        value: mysql-otel-collector
        action: insert
      - key: instrumentation.version
        value: ${env:SERVICE_VERSION:-2.0.0}
        action: insert
      - key: instrumentation.provider
        value: opentelemetry
        action: insert
      - key: pipeline.type
        value: standard
        action: insert

  # New Relic attributes for critical pipeline
  attributes/newrelic_critical:
    actions:
      - key: newrelic.source
        value: opentelemetry
        action: insert
      - key: instrumentation.name
        value: mysql-otel-collector
        action: insert
      - key: instrumentation.version
        value: ${env:SERVICE_VERSION:-2.0.0}
        action: insert
      - key: instrumentation.provider
        value: opentelemetry
        action: insert
      - key: pipeline.type
        value: critical
        action: insert
      - key: priority
        value: high
        action: insert

  # Standardized entity synthesis for New Relic One
  attributes/entity_synthesis:
    actions:
      - key: entity.type
        value: MYSQL_INSTANCE
        action: insert
      - key: entity.guid
        value: MYSQL|${env:CLUSTER_NAME}|${env:MYSQL_ENDPOINT}
        action: insert
      - key: entity.name
        value: ${env:MYSQL_ENDPOINT}
        action: insert
      - key: newrelic.entity.synthesis
        value: "true"
        action: insert

  # Core metrics specific transforms
  transform/core_metrics:
    error_mode: ignore
    metric_statements:
      - context: metric
        statements:
          # Mark critical metrics
          - set(attributes["critical"], true) where name matches "mysql\\.connections\\.current|mysql\\.threads\\.running"
          
          # Add performance categorization
          - set(attributes["performance_category"], "connection_health") where name matches "mysql\\.connections\\.*"
          - set(attributes["performance_category"], "thread_management") where name matches "mysql\\.threads\\.*"
          - set(attributes["performance_category"], "buffer_pool") where name matches "mysql\\.buffer_pool\\.*"
          - set(attributes["performance_category"], "innodb_operations") where name matches "mysql\\.operations\\.*"
          
          # Add alerting thresholds
          - set(attributes["alert_threshold_high"], 80) where name == "mysql.connections.current"
          - set(attributes["alert_threshold_critical"], 95) where name == "mysql.connections.current"
          - set(attributes["alert_threshold_high"], 100) where name == "mysql.threads.running"
          - set(attributes["alert_threshold_critical"], 200) where name == "mysql.threads.running"

  # Filter for critical metrics only
  filter/critical:
    error_mode: ignore
    metrics:
      metric:
        - 'attributes["critical"] == true'

exporters:
  # Primary New Relic OTLP exporter (standard pipeline)
  otlphttp/newrelic_standard:
    endpoint: ${env:NEW_RELIC_OTLP_ENDPOINT}
    headers:
      api-key: ${env:NEW_RELIC_LICENSE_KEY}
    compression: gzip
    timeout: 30s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 60s
      max_elapsed_time: 300s
      randomization_factor: 0.1
      multiplier: 1.5
    sending_queue:
      enabled: true
      num_consumers: 5
      queue_size: ${env:QUEUE_SIZE_STANDARD:-10000}

  # Critical New Relic OTLP exporter (high priority, no compression)
  otlphttp/newrelic_critical:
    endpoint: ${env:NEW_RELIC_OTLP_ENDPOINT}
    headers:
      api-key: ${env:NEW_RELIC_LICENSE_KEY}
    compression: none
    timeout: 10s
    retry_on_failure:
      enabled: true
      initial_interval: 2s
      max_interval: 20s
      max_elapsed_time: 120s
      randomization_factor: 0.05
      multiplier: 2.0
    sending_queue:
      enabled: true
      num_consumers: 3
      queue_size: ${env:QUEUE_SIZE_CRITICAL:-5000}

  # Debug exporter for troubleshooting
  debug:
    verbosity: ${env:DEBUG_VERBOSITY:-basic}
    sampling_initial: 10
    sampling_thereafter: 100

  # Prometheus exporter for federation
  prometheus:
    endpoint: "0.0.0.0:${env:EXPORT_PORT:-8081}"
    namespace: core_metrics
    const_labels:
      module: core-metrics
      cluster: ${env:CLUSTER_NAME}

  # File exporter for persistent storage and backup
  file/backup:
    path: /tmp/core-metrics-backup.jsonl
    rotation:
      max_megabytes: 100
      max_days: 7
      max_backups: 3

extensions:
  # WARNING: DO NOT ADD health_check extension here!
  # Health checks have been intentionally removed from production code.
  # Use shared/validation/health-check-all.sh for validation purposes.
  # See shared/validation/README-health-check.md for details.
  # Health check with comprehensive pipeline monitoring

  # Performance profiling
  pprof:
    endpoint: 0.0.0.0:1777

  # Z-pages for debugging
  zpages:
    endpoint: 0.0.0.0:55679

  # Persistent storage for standard queue
  file_storage/standard:
    directory: /tmp/core-metrics-queue-standard
    timeout: 10s
    compaction:
      directory: /tmp/core-metrics-queue-standard-compact
      on_start: true
      on_rebound: true
      rebound_needed_threshold_mib: 100
      rebound_trigger_threshold_mib: 10

  # Persistent storage for critical queue
  file_storage/critical:
    directory: /tmp/core-metrics-queue-critical
    timeout: 5s
    compaction:
      directory: /tmp/core-metrics-queue-critical-compact
      on_start: true
      on_rebound: true
      rebound_needed_threshold_mib: 50
      rebound_trigger_threshold_mib: 5

service:
  # WARNING: DO NOT ADD health_check to extensions list!
  # Health checks are validation-only, not production features.
  extensions: [pprof, zpages, file_storage/standard, file_storage/critical]  # NO health_check here!pprof, zpages, file_storage/standard, file_storage/critical
  pipelines:
    # Standard pipeline for regular metrics
    metrics/standard:
      receivers: [mysql]
      processors: [
        memory_limiter,
        batch/standard,
        attributes/core_metrics,
        resource/standard,
        attributes/newrelic,
        attributes/entity_synthesis,
        transform/core_metrics
      ]
      exporters: [otlphttp/newrelic_standard, prometheus, file/backup]

    # Critical pipeline for high-priority alerts
    metrics/critical:
      receivers: [mysql]
      processors: [
        memory_limiter,
        filter/critical,
        batch/critical,
        attributes/core_metrics,
        resource/standard,
        attributes/newrelic_critical,
        attributes/entity_synthesis
      ]
      exporters: [otlphttp/newrelic_critical]

    # Debug pipeline for troubleshooting
    metrics/debug:
      receivers: [mysql]
      processors: [memory_limiter, attributes/core_metrics]
      exporters: [debug]

    # Federation pipeline for cross-module correlation
    metrics/federation:
      receivers: [prometheus/federation]
      processors: [
        memory_limiter,
        batch/standard,
        attributes/core_metrics,
        resource/standard,
        attributes/newrelic
      ]
      exporters: [otlphttp/newrelic_standard]

  # Telemetry configuration
  telemetry:
    logs:
      level: ${env:LOG_LEVEL:-info}
      development: false
      encoding: json
      disable_caller: false
      disable_stacktrace: false
      output_paths: ["stdout", "/tmp/core-metrics-otel.log"]
      error_output_paths: ["stderr"]
    
    metrics:
      level: detailed
      
    resource:
      service.name: otelcol-contrib
      service.version: 0.130.0
