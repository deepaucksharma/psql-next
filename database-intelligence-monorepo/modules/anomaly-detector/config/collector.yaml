receivers:
  # Prometheus federation receiver to pull metrics from other modules
  prometheus:
    config:
      scrape_configs:
        - job_name: 'core-metrics-federation'
          scrape_interval: 10s
          static_configs:
            - targets: ['${env:CORE_METRICS_ENDPOINT}']
          metric_relabel_configs:
            - source_labels: [__name__]
              regex: 'mysql_.*'
              action: keep
              
        - job_name: 'sql-intelligence-federation'
          scrape_interval: 10s
          static_configs:
            - targets: ['${env:SQL_INTELLIGENCE_ENDPOINT}']
          metric_relabel_configs:
            - source_labels: [__name__]
              regex: '(mysql_query_.*|mysql_slow_.*|mysql_plan_.*)'
              action: keep
              
        - job_name: 'wait-profiler-federation'
          scrape_interval: 10s
          static_configs:
            - targets: ['${env:WAIT_PROFILER_ENDPOINT}']
          metric_relabel_configs:
            - source_labels: [__name__]
              regex: 'mysql_wait_.*'
              action: keep

processors:
  batch:
    timeout: 5s
    send_batch_size: 1000
  
  # Transform processor for anomaly detection using statistical methods
  transform/anomaly_detection:
    error_mode: ignore
    metric_statements:
      # Connection spike detection
      - context: metric
        statements:
          - set(name, "anomaly_score_connections") where name == "mysql_connections_current"
          - set(attributes["anomaly_type"], "connection_spike") where name == "anomaly_score_connections"
          - set(value, (value - attributes["baseline_mean"]) / attributes["baseline_stddev"]) where name == "anomaly_score_connections" and attributes["baseline_stddev"] != nil and attributes["baseline_stddev"] > 0
          
      # Query latency deviation detection
      - context: metric
        statements:
          - set(name, "anomaly_score_query_latency") where name == "mysql_query_duration_milliseconds"
          - set(attributes["anomaly_type"], "latency_deviation") where name == "anomaly_score_query_latency"
          - set(value, (value - attributes["baseline_mean"]) / attributes["baseline_stddev"]) where name == "anomaly_score_query_latency" and attributes["baseline_stddev"] != nil and attributes["baseline_stddev"] > 0
          
      # Wait event anomaly detection
      - context: metric
        statements:
          - set(name, "anomaly_score_wait_events") where name == "mysql_wait_time_total"
          - set(attributes["anomaly_type"], "wait_anomaly") where name == "anomaly_score_wait_events"
          - set(value, (value - attributes["baseline_mean"]) / attributes["baseline_stddev"]) where name == "anomaly_score_wait_events" and attributes["baseline_stddev"] != nil and attributes["baseline_stddev"] > 0
          
      # Resource usage pattern detection
      - context: metric
        statements:
          - set(name, "anomaly_score_cpu") where name == "mysql_cpu_percent"
          - set(attributes["anomaly_type"], "resource_usage") where name == "anomaly_score_cpu"
          - set(value, (value - attributes["baseline_mean"]) / attributes["baseline_stddev"]) where name == "anomaly_score_cpu" and attributes["baseline_stddev"] != nil and attributes["baseline_stddev"] > 0

  # Generate alerts based on anomaly scores
  transform/anomaly_alerts:
    error_mode: ignore
    metric_statements:
      - context: metric
        statements:
          # Create alert metric for connection spikes
          - set(name, "anomaly_alert") where name == "anomaly_score_connections" and value > ${env:CONNECTION_SPIKE_THRESHOLD}
          - set(attributes["alert_severity"], "high") where name == "anomaly_alert" and attributes["anomaly_type"] == "connection_spike"
          - set(value, 1) where name == "anomaly_alert"
          
          # Create alert metric for latency deviations
          - set(name, "anomaly_alert") where name == "anomaly_score_query_latency" and value > ${env:LATENCY_DEVIATION_THRESHOLD}
          - set(attributes["alert_severity"], "critical") where name == "anomaly_alert" and attributes["anomaly_type"] == "latency_deviation"
          - set(value, 1) where name == "anomaly_alert"
          
          # Create alert metric for wait anomalies
          - set(name, "anomaly_alert") where name == "anomaly_score_wait_events" and value > ${env:WAIT_EVENT_THRESHOLD}
          - set(attributes["alert_severity"], "medium") where name == "anomaly_alert" and attributes["anomaly_type"] == "wait_anomaly"
          - set(value, 1) where name == "anomaly_alert"
          
          # Create alert metric for resource usage
          - set(name, "anomaly_alert") where name == "anomaly_score_cpu" and value > ${env:RESOURCE_USAGE_THRESHOLD}
          - set(attributes["alert_severity"], "medium") where name == "anomaly_alert" and attributes["anomaly_type"] == "resource_usage"
          - set(value, 1) where name == "anomaly_alert"

  # Add baseline calculation (simplified - in production use a more sophisticated approach)
  transform/baseline_enrichment:
    error_mode: ignore
    metric_statements:
      - context: metric
        statements:
          # Add baseline metadata (these would normally come from a baseline service)
          - set(attributes["baseline_mean"], 100) where name == "mysql_connections_current"
          - set(attributes["baseline_stddev"], 20) where name == "mysql_connections_current"
          - set(attributes["baseline_mean"], 50) where name == "mysql_query_duration_milliseconds"
          - set(attributes["baseline_stddev"], 15) where name == "mysql_query_duration_milliseconds"
          - set(attributes["baseline_mean"], 1000) where name == "mysql_wait_time_total"
          - set(attributes["baseline_stddev"], 300) where name == "mysql_wait_time_total"
          - set(attributes["baseline_mean"], 50) where name == "mysql_cpu_percent"
          - set(attributes["baseline_stddev"], 10) where name == "mysql_cpu_percent"

  attributes:
    actions:
      - key: module
        value: anomaly-detector
        action: insert
      - key: detection_method
        value: statistical_zscore
        action: insert

  resource:
    attributes:
      - key: service.name
        value: ${env:OTEL_SERVICE_NAME}
        action: upsert

exporters:
  prometheus:
    endpoint: "0.0.0.0:${env:EXPORT_PORT}"
    namespace: anomaly
    const_labels:
      module: anomaly-detector
  
  logging:
    loglevel: info
    
  # Export alerts to a file (in production, use alertmanager or similar)
  file:
    path: /tmp/anomaly_alerts.json
    format: json

service:
  pipelines:
    metrics:
      receivers: [prometheus]
      processors: [batch, transform/baseline_enrichment, transform/anomaly_detection, transform/anomaly_alerts, attributes, resource]
      exporters: [prometheus, logging]
    
    # Separate pipeline for alerts
    metrics/alerts:
      receivers: [prometheus]
      processors: [batch, transform/baseline_enrichment, transform/anomaly_detection, transform/anomaly_alerts]
      exporters: [file, logging]
  
  extensions: [health_check]

extensions:
  health_check:
    endpoint: 0.0.0.0:13133