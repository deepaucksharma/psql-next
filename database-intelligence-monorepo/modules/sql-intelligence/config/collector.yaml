receivers:
  sqlquery/slow_queries:
    driver: mysql
    datasource: "${env:MYSQL_USER}:${env:MYSQL_PASSWORD}@tcp(${env:MYSQL_ENDPOINT})/"
    collection_interval: 15s
    queries:
      - sql: |
          SELECT 
            DIGEST,
            SCHEMA_NAME,
            DIGEST_TEXT,
            COUNT_STAR as exec_count,
            SUM_TIMER_WAIT/1000000000000 as total_latency_sec,
            AVG_TIMER_WAIT/1000000000000 as avg_latency_sec,
            MAX_TIMER_WAIT/1000000000000 as max_latency_sec,
            SUM_ROWS_EXAMINED as rows_examined_total,
            SUM_ROWS_SENT as rows_sent_total,
            SUM_NO_INDEX_USED as no_index_used_count,
            SUM_NO_GOOD_INDEX_USED as no_good_index_count
          FROM performance_schema.events_statements_summary_by_digest
          WHERE SCHEMA_NAME IS NOT NULL
            AND DIGEST_TEXT NOT LIKE '%performance_schema%'
            AND COUNT_STAR > 0
          ORDER BY total_latency_sec DESC
          LIMIT 20
        metrics:
          - metric_name: mysql.query.exec_count
            value_column: exec_count
            attribute_columns: [DIGEST, SCHEMA_NAME, DIGEST_TEXT]
          - metric_name: mysql.query.latency.total
            value_column: total_latency_sec
            attribute_columns: [DIGEST, SCHEMA_NAME, DIGEST_TEXT]
          - metric_name: mysql.query.latency.avg
            value_column: avg_latency_sec
            attribute_columns: [DIGEST, SCHEMA_NAME, DIGEST_TEXT]
          - metric_name: mysql.query.latency.max
            value_column: max_latency_sec
            attribute_columns: [DIGEST, SCHEMA_NAME, DIGEST_TEXT]
          - metric_name: mysql.query.rows_examined
            value_column: rows_examined_total
            attribute_columns: [DIGEST, SCHEMA_NAME, DIGEST_TEXT]
          - metric_name: mysql.query.no_index_used
            value_column: no_index_used_count
            attribute_columns: [DIGEST, SCHEMA_NAME, DIGEST_TEXT]
  
  sqlquery/table_stats:
    driver: mysql
    datasource: "${env:MYSQL_USER}:${env:MYSQL_PASSWORD}@tcp(${env:MYSQL_ENDPOINT})/"
    collection_interval: 30s
    queries:
      - sql: |
          SELECT 
            OBJECT_SCHEMA,
            OBJECT_NAME,
            SUM_TIMER_READ/1000000000000 as read_latency_sec,
            SUM_TIMER_WRITE/1000000000000 as write_latency_sec,
            SUM_TIMER_MISC/1000000000000 as misc_latency_sec,
            COUNT_READ as read_count,
            COUNT_WRITE as write_count,
            COUNT_MISC as misc_count
          FROM performance_schema.table_io_waits_summary_by_table
          WHERE OBJECT_SCHEMA NOT IN ('mysql', 'performance_schema', 'information_schema', 'sys')
          ORDER BY (SUM_TIMER_READ + SUM_TIMER_WRITE) DESC
          LIMIT 20
        metrics:
          - metric_name: mysql.table.io.read_latency
            value_column: read_latency_sec
            attribute_columns: [OBJECT_SCHEMA, OBJECT_NAME]
          - metric_name: mysql.table.io.write_latency
            value_column: write_latency_sec
            attribute_columns: [OBJECT_SCHEMA, OBJECT_NAME]
          - metric_name: mysql.table.io.read_count
            value_column: read_count
            attribute_columns: [OBJECT_SCHEMA, OBJECT_NAME]
          - metric_name: mysql.table.io.write_count
            value_column: write_count
            attribute_columns: [OBJECT_SCHEMA, OBJECT_NAME]

  sqlquery/index_usage:
    driver: mysql
    datasource: "${env:MYSQL_USER}:${env:MYSQL_PASSWORD}@tcp(${env:MYSQL_ENDPOINT})/"
    collection_interval: 60s
    queries:
      - sql: |
          SELECT 
            TABLE_SCHEMA,
            TABLE_NAME,
            INDEX_NAME,
            CARDINALITY,
            SEQ_IN_INDEX
          FROM information_schema.STATISTICS
          WHERE TABLE_SCHEMA NOT IN ('mysql', 'performance_schema', 'information_schema', 'sys')
            AND INDEX_NAME != 'PRIMARY'
          ORDER BY CARDINALITY DESC
          LIMIT 50
        metrics:
          - metric_name: mysql.index.cardinality
            value_column: CARDINALITY
            attribute_columns: [TABLE_SCHEMA, TABLE_NAME, INDEX_NAME]

  # Optional: Pull metrics from core-metrics if available
  prometheus:
    config:
      scrape_configs:
        - job_name: 'metrics-federation'
          scrape_interval: 30s
          static_configs:
            - targets: ['${env:METRICS_ENDPOINT}']
          metric_relabel_configs:
            - source_labels: [__name__]
              regex: 'mysql_.*'
              action: keep

processors:
  # Memory management
  memory_limiter:
    check_interval: 5s
    limit_percentage: 80
    spike_limit_percentage: 30

  batch:
    timeout: 5s
    send_batch_size: 1000
  
  attributes:
    actions:
      - key: module
        value: sql-intelligence
        action: insert
      - key: mysql.endpoint
        value: ${env:MYSQL_ENDPOINT}
        action: insert
  
  # New Relic specific attributes
  attributes/newrelic:
    actions:
      - key: newrelic.source
        value: opentelemetry
        action: insert
      - key: instrumentation.name
        value: mysql-otel-collector
        action: insert
      - key: instrumentation.version
        value: "2.0.0"
        action: insert
      - key: instrumentation.provider
        value: opentelemetry
        action: insert
      - key: environment
        value: ${env:ENVIRONMENT}
        action: insert

  # Entity synthesis for New Relic One
  attributes/entity_synthesis:
    actions:
      - key: entity.type
        value: "MYSQL_INSTANCE"
        action: insert
      - key: entity.guid
        value: "MYSQL|${env:CLUSTER_NAME}|${env:MYSQL_ENDPOINT}"
        action: insert
      - key: entity.name
        value: "${env:MYSQL_ENDPOINT}"
        action: insert
      - key: newrelic.entity.synthesis
        value: "true"
        action: insert
  
  transform/query_analysis:
    metric_statements:
      - context: datapoint
        statements:
          - set(attributes["query_type"], 
                Case(
                  IsMatch(attributes["DIGEST_TEXT"], "(?i)^SELECT.*"), "SELECT",
                  IsMatch(attributes["DIGEST_TEXT"], "(?i)^INSERT.*"), "INSERT",
                  IsMatch(attributes["DIGEST_TEXT"], "(?i)^UPDATE.*"), "UPDATE",
                  IsMatch(attributes["DIGEST_TEXT"], "(?i)^DELETE.*"), "DELETE",
                  "OTHER"
                )) where attributes["DIGEST_TEXT"] != nil
          - set(attributes["needs_optimization"], 
                Case(
                  attributes["no_index_used_count"] > 0, "true",
                  attributes["avg_latency_sec"] > 1, "true",
                  "false"
                )) where attributes["avg_latency_sec"] != nil
      - context: metric
        statements:
          # Add event type for NRQL queries
          - set(attributes["eventType"], "MySQLQuery")
          # Mark high-value metrics
          - set(attributes["nr.highValue"], true)
            where name == "mysql.query.no_index_used" or 
                  name == "mysql.query.latency.max"

  resource:
    attributes:
      - key: service.name
        value: ${env:OTEL_SERVICE_NAME}
        action: upsert

exporters:
  # Primary New Relic OTLP exporter for standard metrics
  otlphttp/newrelic_standard:
    endpoint: ${env:NEW_RELIC_OTLP_ENDPOINT}
    headers:
      api-key: ${env:NEW_RELIC_LICENSE_KEY}
    compression: gzip
    timeout: 30s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
    sending_queue:
      enabled: true
      num_consumers: 5
      queue_size: 10000

  # High-priority exporter for critical SQL metrics
  otlphttp/newrelic_critical:
    endpoint: ${env:NEW_RELIC_OTLP_ENDPOINT}
    headers:
      api-key: ${env:NEW_RELIC_LICENSE_KEY}
      X-Priority: critical
    compression: none  # No compression for lower latency
    timeout: 10s
    retry_on_failure:
      enabled: true
      initial_interval: 1s
      max_interval: 10s
      max_elapsed_time: 60s
  
  debug:
    verbosity: detailed
    sampling_initial: 10
    sampling_thereafter: 100

service:
  pipelines:
    metrics/queries:
      receivers: [sqlquery/slow_queries, sqlquery/table_stats, sqlquery/index_usage]
      processors: [memory_limiter, batch, attributes, attributes/newrelic, attributes/entity_synthesis, transform/query_analysis, resource]
      exporters: [otlphttp/newrelic_standard, debug]
    
    metrics/federation:
      receivers: [prometheus]
      processors: [memory_limiter, batch, attributes, attributes/newrelic, resource]
      exporters: [otlphttp/newrelic_standard]
  
  extensions: [health_check]

extensions:
  health_check:
    endpoint: 0.0.0.0:13133