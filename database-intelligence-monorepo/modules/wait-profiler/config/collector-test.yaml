receivers:
  sqlquery/wait_events:
    driver: mysql
    datasource: "${env:MYSQL_USER}:${env:MYSQL_PASSWORD}@tcp(${env:MYSQL_ENDPOINT})/performance_schema"
    collection_interval: 5s
    queries:
      - sql: |
          SELECT 
            EVENT_NAME,
            COUNT_STAR as wait_count,
            SUM_TIMER_WAIT/1000000000 as total_wait_ms,
            AVG_TIMER_WAIT/1000000000 as avg_wait_ms,
            MAX_TIMER_WAIT/1000000000 as max_wait_ms
          FROM performance_schema.events_waits_summary_global_by_event_name
          WHERE COUNT_STAR > 0
            AND EVENT_NAME NOT LIKE 'idle%'
          ORDER BY SUM_TIMER_WAIT DESC
          LIMIT 50
        metrics:
          - metric_name: mysql.wait.count
            value_column: wait_count
            attribute_columns: [EVENT_NAME]
          - metric_name: mysql.wait.time_ms
            value_column: total_wait_ms
            attribute_columns: [EVENT_NAME]
          - metric_name: mysql.wait.time_avg_ms
            value_column: avg_wait_ms
            attribute_columns: [EVENT_NAME]
          - metric_name: mysql.wait.time_max_ms
            value_column: max_wait_ms
            attribute_columns: [EVENT_NAME]
  
  sqlquery/mutex_waits:
    driver: mysql
    datasource: "${env:MYSQL_USER}:${env:MYSQL_PASSWORD}@tcp(${env:MYSQL_ENDPOINT})/performance_schema"
    collection_interval: 10s
    queries:
      - sql: |
          SELECT 
            OBJECT_NAME as mutex_name,
            COUNT_STAR as wait_count,
            SUM_TIMER_WAIT/1000000000 as total_wait_ms,
            AVG_TIMER_WAIT/1000000000 as avg_wait_ms
          FROM performance_schema.events_waits_summary_by_instance
          WHERE OBJECT_NAME IS NOT NULL
            AND COUNT_STAR > 0
          ORDER BY SUM_TIMER_WAIT DESC
          LIMIT 20
        metrics:
          - metric_name: mysql.wait.mutex.count
            value_column: wait_count
            attribute_columns: [mutex_name]
          - metric_name: mysql.wait.mutex.time_ms
            value_column: total_wait_ms
            attribute_columns: [mutex_name]
  
  sqlquery/io_waits:
    driver: mysql
    datasource: "${env:MYSQL_USER}:${env:MYSQL_PASSWORD}@tcp(${env:MYSQL_ENDPOINT})/performance_schema"
    collection_interval: 10s
    queries:
      - sql: |
          SELECT 
            FILE_NAME,
            EVENT_NAME,
            COUNT_STAR as io_count,
            SUM_TIMER_WAIT/1000000000 as total_io_wait_ms,
            COUNT_READ as read_count,
            COUNT_WRITE as write_count,
            SUM_NUMBER_OF_BYTES_READ as bytes_read,
            SUM_NUMBER_OF_BYTES_WRITE as bytes_written
          FROM performance_schema.file_summary_by_event_name
          WHERE COUNT_STAR > 0
            AND FILE_NAME IS NOT NULL
          ORDER BY SUM_TIMER_WAIT DESC
          LIMIT 30
        metrics:
          - metric_name: mysql.wait.io.count
            value_column: io_count
            attribute_columns: [FILE_NAME, EVENT_NAME]
          - metric_name: mysql.wait.io.time_ms
            value_column: total_io_wait_ms
            attribute_columns: [FILE_NAME, EVENT_NAME]
          - metric_name: mysql.io.bytes_read
            value_column: bytes_read
            attribute_columns: [FILE_NAME]
          - metric_name: mysql.io.bytes_written
            value_column: bytes_written
            attribute_columns: [FILE_NAME]
  
  sqlquery/lock_waits:
    driver: mysql
    datasource: "${env:MYSQL_USER}:${env:MYSQL_PASSWORD}@tcp(${env:MYSQL_ENDPOINT})/performance_schema"
    collection_interval: 5s
    queries:
      - sql: |
          SELECT 
            OBJECT_SCHEMA,
            OBJECT_NAME,
            INDEX_NAME,
            LOCK_TYPE,
            LOCK_MODE,
            COUNT(*) as lock_count
          FROM performance_schema.data_locks
          WHERE OBJECT_SCHEMA NOT IN ('mysql', 'performance_schema', 'information_schema', 'sys')
          GROUP BY OBJECT_SCHEMA, OBJECT_NAME, INDEX_NAME, LOCK_TYPE, LOCK_MODE
        metrics:
          - metric_name: mysql.lock.active_count
            value_column: lock_count
            attribute_columns: [OBJECT_SCHEMA, OBJECT_NAME, INDEX_NAME, LOCK_TYPE, LOCK_MODE]

processors:
  # Memory management
  memory_limiter:
    check_interval: 5s
    limit_percentage: 80
    spike_limit_percentage: 30

  batch:
    timeout: 5s
    send_batch_size: 1000
  
  attributes:
    actions:
      - key: module
        value: wait-profiler
        action: insert
      - key: mysql.endpoint
        value: ${env:MYSQL_ENDPOINT}
        action: insert
  
  transform/wait_categorization:
    error_mode: ignore
    metric_statements:
      - context: datapoint
        statements:
          # Categorize wait events based on EVENT_NAME patterns
          # Events starting with "wait/io/" should be categorized as "io"
          - set(attributes["wait_category"], "io") where attributes["EVENT_NAME"] != nil and IsMatch(attributes["EVENT_NAME"], "^wait/io/.*")
          
          # Events starting with "wait/lock/" should be categorized as "lock"
          - set(attributes["wait_category"], "lock") where attributes["EVENT_NAME"] != nil and attributes["wait_category"] == nil and IsMatch(attributes["EVENT_NAME"], "^wait/lock/.*")
          
          # Events starting with "wait/synch/mutex/" should be categorized as "mutex"
          - set(attributes["wait_category"], "mutex") where attributes["EVENT_NAME"] != nil and attributes["wait_category"] == nil and IsMatch(attributes["EVENT_NAME"], "^wait/synch/mutex/.*")
          
          # Events starting with "wait/synch/cond/" should be categorized as "condition"
          - set(attributes["wait_category"], "condition") where attributes["EVENT_NAME"] != nil and attributes["wait_category"] == nil and IsMatch(attributes["EVENT_NAME"], "^wait/synch/cond/.*")
          
          # Events containing "net" should be categorized as "network"
          - set(attributes["wait_category"], "network") where attributes["EVENT_NAME"] != nil and attributes["wait_category"] == nil and IsMatch(attributes["EVENT_NAME"], ".*net.*")
          
          # All others should be "other"
          - set(attributes["wait_category"], "other") where attributes["EVENT_NAME"] != nil and attributes["wait_category"] == nil
          
          # Set severity based on wait time
          - set(attributes["severity"], "critical") where attributes["avg_wait_ms"] != nil and attributes["avg_wait_ms"] > 1000
          - set(attributes["severity"], "warning") where attributes["severity"] == nil and attributes["avg_wait_ms"] != nil and attributes["avg_wait_ms"] > 100
          - set(attributes["severity"], "normal") where attributes["severity"] == nil and attributes["avg_wait_ms"] != nil

  resource:
    attributes:
      - key: service.name
        value: ${env:OTEL_SERVICE_NAME}
        action: upsert

exporters:
  # Prometheus exporter for metrics
  prometheus:
    endpoint: 0.0.0.0:8889
    
  debug:
    verbosity: detailed
    sampling_initial: 10
    sampling_thereafter: 100

service:
  pipelines:
    metrics:
      receivers: [sqlquery/wait_events, sqlquery/mutex_waits, sqlquery/io_waits, sqlquery/lock_waits]
      processors: [memory_limiter, batch, attributes, transform/wait_categorization, resource]
      exporters: [prometheus, debug]
  
  # WARNING: DO NOT ADD health_check to extensions list!
  
  # Health checks are validation-only, not production features.
  
  extensions: []  # NO health_check here!
extensions:
  # WARNING: DO NOT ADD health_check extension here!
  # Health checks have been intentionally removed from production code.
  # Use shared/validation/health-check-all.sh for validation purposes.
  # See shared/validation/README-health-check.md for details.
