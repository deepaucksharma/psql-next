# Database Intelligence - Unified Complete Configuration
# This configuration includes ALL processors, receivers, and exporters for full testing
# Use this for comprehensive E2E testing and demonstration

receivers:
  # Standard OTEL Receivers
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  # Database Receivers
  postgresql:
    endpoint: ${DB_POSTGRES_HOST:-localhost}:${DB_POSTGRES_PORT:-5432}
    transport: tcp
    username: ${DB_POSTGRES_USER:-postgres}
    password: ${DB_POSTGRES_PASSWORD:-password}
    databases:
      - ${DB_POSTGRES_DATABASE:-testdb}
    collection_interval: 10s
    initial_delay: 1s
    tls:
      insecure: true

  mysql:
    endpoint: ${DB_MYSQL_HOST:-localhost}:${DB_MYSQL_PORT:-3306}
    transport: tcp  
    username: ${DB_MYSQL_USER:-root}
    password: ${DB_MYSQL_PASSWORD:-password}
    database: ${DB_MYSQL_DATABASE:-testdb}
    collection_interval: 10s
    initial_delay: 1s
    tls:
      insecure: true

  # Custom SQL Query Receiver
  sqlquery:
    driver: postgres
    datasource: "postgres://${DB_POSTGRES_USER:-postgres}:${DB_POSTGRES_PASSWORD:-password}@${DB_POSTGRES_HOST:-localhost}:${DB_POSTGRES_PORT:-5432}/${DB_POSTGRES_DATABASE:-testdb}?sslmode=disable"
    collection_interval: 30s
    queries:
      - sql: "SELECT schemaname, tablename, n_tup_ins, n_tup_upd, n_tup_del FROM pg_stat_user_tables"
        metrics:
          - metric_name: postgresql_table_modifications
            value_column: n_tup_ins
            attribute_columns: ["schemaname", "tablename"]
            static_attributes:
              modification_type: "inserts"
          - metric_name: postgresql_table_modifications  
            value_column: n_tup_upd
            attribute_columns: ["schemaname", "tablename"]
            static_attributes:
              modification_type: "updates"
          - metric_name: postgresql_table_modifications
            value_column: n_tup_del
            attribute_columns: ["schemaname", "tablename"] 
            static_attributes:
              modification_type: "deletes"

  # Custom Receivers (when available)
  enhancedsql:
    enabled: true
    endpoint: ${DB_POSTGRES_HOST:-localhost}:${DB_POSTGRES_PORT:-5432}
    username: ${DB_POSTGRES_USER:-postgres}
    password: ${DB_POSTGRES_PASSWORD:-password}
    database: ${DB_POSTGRES_DATABASE:-testdb}
    collection_interval: 15s
    query_timeout: 30s
    features:
      - query_analysis
      - plan_extraction
      - performance_metrics

processors:
  # Memory limiter (always first)
  memory_limiter:
    limit_mib: 512
    spike_limit_mib: 128
    check_interval: 5s

  # Batch processor for efficiency
  batch:
    send_batch_size: 1024
    send_batch_max_size: 2048
    timeout: 10s

  # Custom Database Intelligence Processors
  
  # Adaptive Sampler - Intelligent sampling for high-volume environments
  adaptivesampler:
    enabled: true
    default_sampling_rate: 0.1  # 10% default sampling
    max_sampling_rate: 1.0      # 100% max
    min_sampling_rate: 0.01     # 1% min
    cache_size: 10000
    cache_ttl: 300s
    rules:
      - name: "high_priority_queries"
        condition: 'attributes["query.priority"] == "high" || attributes["query.duration_ms"] > 5000'
        sampling_rate: 1.0
      - name: "error_queries"
        condition: 'attributes["query.status"] == "error"'
        sampling_rate: 1.0
      - name: "slow_queries"
        condition: 'attributes["query.duration_ms"] > 1000'
        sampling_rate: 0.5
      - name: "frequent_patterns"
        condition: 'attributes["query.pattern_hash"] != nil'
        sampling_rate: 0.05

  # Circuit Breaker - Protect downstream systems
  circuit_breaker:
    enabled: true
    failure_threshold: 5
    recovery_timeout: 30s
    half_open_max_requests: 3
    metrics_evaluation_interval: 10s
    circuit_breaker_rules:
      - name: "database_health"
        metric_name: "postgresql_up"
        threshold: 0.5
        operator: "less_than"
      - name: "connection_errors"
        metric_name: "postgresql_connection_errors_total"
        threshold: 10
        operator: "greater_than"
        time_window: 60s

  # Cost Control - Manage data volume and costs
  costcontrol:
    enabled: true
    daily_budget_usd: 100.0
    pricing_tiers:
      - up_to: 1000000      # 1M metrics
        price_per_million: 0.25
      - up_to: 10000000     # 10M metrics
        price_per_million: 0.20
      - up_to: 100000000    # 100M metrics
        price_per_million: 0.15
      - up_to: -1           # Unlimited
        price_per_million: 0.10
    cost_reduction_strategies:
      - strategy: "reduce_sampling"
        trigger_percentage: 80.0
        action:
          sampling_rate_multiplier: 0.5
      - strategy: "drop_low_priority"
        trigger_percentage: 90.0
        action:
          drop_attributes: ["query.explain_plan", "query.full_text"]
      - strategy: "emergency_mode"
        trigger_percentage: 95.0
        action:
          sampling_rate_multiplier: 0.1
          drop_metric_types: ["histogram", "summary"]

  # Plan Attribute Extractor - Extract query execution plans
  planattributeextractor:
    enabled: true
    include_plan_details: true
    anonymize_queries: true
    max_plan_size_kb: 64
    plan_cache_size: 1000
    plan_cache_ttl: 3600s
    extraction_rules:
      - plan_type: "postgresql"
        extract_costs: true
        extract_timing: true
        extract_operators: true
        max_depth: 10
      - plan_type: "mysql"
        extract_costs: true
        extract_timing: false
        extract_operators: true
        max_depth: 8

  # Verification - Data quality and PII detection
  verification:
    enabled: true
    max_cardinality: 50000
    pii_detection:
      enabled: true
      patterns:
        - name: "email"
          regex: '\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
          replacement: "REDACTED_EMAIL"
        - name: "phone"
          regex: '\b(?:\+?1[-.\s]?)?\(?[0-9]{3}\)?[-.\s]?[0-9]{3}[-.\s]?[0-9]{4}\b'
          replacement: "REDACTED_PHONE"
        - name: "ssn"
          regex: '\b\d{3}-?\d{2}-?\d{4}\b'
          replacement: "REDACTED_SSN"
        - name: "credit_card"
          regex: '\b(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|3[47][0-9]{13}|3[0-9]{13}|6(?:011|5[0-9]{2})[0-9]{12})\b'
          replacement: "REDACTED_CC"
    data_quality_checks:
      - name: "required_attributes"
        required_fields: ["db.name", "db.operation", "db.sql.table"]
      - name: "timestamp_validation"
        max_future_drift: 300s
      - name: "numeric_validation"
        check_negative_durations: true

  # NR Error Monitor - New Relic specific error handling
  nrerrormonitor:
    enabled: true
    error_patterns:
      - pattern: "rate limit exceeded"
        action: "reduce_throughput"
        severity: "warning"
        throttle_factor: 0.5
      - pattern: "invalid api key"
        action: "stop_export"
        severity: "critical"
      - pattern: "request entity too large"
        action: "reduce_batch_size"
        severity: "warning"
        max_batch_size: 512
    recovery_strategies:
      - error_type: "rate_limit"
        backoff_strategy: "exponential"
        initial_delay: 30s
        max_delay: 300s
        multiplier: 2.0
      - error_type: "payload_size"
        backoff_strategy: "linear"
        batch_size_reduction: 0.25

  # Query Correlator - Correlate related queries and transactions
  querycorrelator:
    enabled: true
    correlation_window: 300s
    max_correlation_cache: 5000
    correlation_rules:
      - name: "transaction_correlation"
        group_by: ["db.connection_id", "db.transaction_id"]
        correlation_timeout: 600s
      - name: "session_correlation"
        group_by: ["db.connection_id", "db.user"]
        correlation_timeout: 1800s
      - name: "query_pattern_correlation"
        group_by: ["query.pattern_hash"]
        correlation_timeout: 300s

  # Resource processor for attribute manipulation
  resource:
    attributes:
      - key: environment
        value: ${ENVIRONMENT:-development}
        action: upsert
      - key: service.name
        value: database-intelligence-collector
        action: upsert
      - key: service.version
        value: 2.0.0
        action: upsert
      - key: deployment.environment
        value: ${ENVIRONMENT:-development}
        action: upsert

  # Transform processor for metric manipulation
  transform:
    error_mode: ignore
    metric_statements:
      - context: metric
        statements:
          - set(description, "Database Intelligence Enhanced Metric") where name == "postgresql_backends"
          - set(unit, "connections") where name == "postgresql_backends"

exporters:
  # Debug exporter for local testing
  debug:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 200

  # OTLP exporter for New Relic - Primary destination
  otlp/newrelic:
    endpoint: ${OTLP_ENDPOINT:-https://otlp.nr-data.net:4317}
    headers:
      api-key: ${NEW_RELIC_LICENSE_KEY}
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 1000
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

  # File exporter for debugging and backup
  file:
    path: ./telemetry-output.json
    rotation:
      max_megabytes: 100
      max_days: 7
      max_backups: 3

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133
    path: /health

  # pprof for performance profiling
  pprof:
    endpoint: 0.0.0.0:1777

  # zpages for observability
  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Primary metrics pipeline - All data to New Relic
    metrics:
      receivers: [postgresql, mysql, sqlquery, enhancedsql, otlp]
      processors: [
        memory_limiter,
        resource,
        adaptivesampler,
        circuit_breaker,
        planattributeextractor,
        verification,
        costcontrol,
        nrerrormonitor,
        querycorrelator,
        transform,
        batch
      ]
      exporters: [debug, otlp/newrelic, file]

    # Traces pipeline
    traces:
      receivers: [otlp]
      processors: [memory_limiter, resource, batch]
      exporters: [debug, otlp/newrelic]

    # Logs pipeline
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resource, batch]
      exporters: [debug, otlp/newrelic]

  telemetry:
    logs:
      level: info
      development: false
      encoding: json
      disable_caller: false
      disable_stacktrace: false
      output_paths: ["stdout"]
      error_output_paths: ["stderr"]
    metrics:
      level: detailed
      address: 0.0.0.0:8888