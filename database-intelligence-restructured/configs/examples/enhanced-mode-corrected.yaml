# Enhanced Mode Configuration with Correct Processor Ordering
# This configuration uses custom receivers and processors for advanced database intelligence
# Requires custom OTel Collector build with enhanced components

# Environment variables required:
# - DB_POSTGRES_HOST: PostgreSQL host
# - DB_POSTGRES_PORT: PostgreSQL port (default: 5432)
# - DB_POSTGRES_USER: PostgreSQL username
# - DB_POSTGRES_PASSWORD: PostgreSQL password
# - DB_POSTGRES_DATABASE: PostgreSQL database name
# - NEW_RELIC_OTLP_ENDPOINT: New Relic OTLP endpoint (default: https://otlp.nr-data.net:4318)
# - NEW_RELIC_LICENSE_KEY: New Relic license key
# - SERVICE_NAME: Service identifier (e.g., postgresql-prod-01)
# - ENVIRONMENT: Environment name (dev/staging/prod)

receivers:
  # Standard PostgreSQL receiver for basic metrics
  postgresql:
    endpoint: "${DB_POSTGRES_HOST}:${DB_POSTGRES_PORT}"
    username: "${DB_POSTGRES_USER}"
    password: "${DB_POSTGRES_PASSWORD}"
    databases:
      - "${DB_POSTGRES_DATABASE}"
    collection_interval: 30s
    transport: tcp
    tls:
      insecure: true  # Set to false in production with proper certs
    initial_delay: 1s

  # Enhanced SQL receiver for advanced query analytics
  enhancedsql:
    endpoint: "${DB_POSTGRES_HOST}:${DB_POSTGRES_PORT}"
    username: "${DB_POSTGRES_USER}"
    password: "${DB_POSTGRES_PASSWORD}"
    database: "${DB_POSTGRES_DATABASE}"
    collection_interval: 10s
    query_timeout: 5s
    max_concurrent_queries: 5
    
    feature_detection:
      enabled: true
      extensions_to_check:
        - pg_stat_statements
        - pg_stat_monitor
        - pg_querylens
    
    queries:
      - name: "slow_queries"
        category: "performance"
        interval: 30s
      - name: "active_sessions"
        category: "sessions"
        interval: 10s
      - name: "wait_events"
        category: "waits"
        interval: 10s
      - name: "table_stats"
        category: "tables"
        interval: 60s

  # Active Session History receiver
  ash:
    endpoint: "${DB_POSTGRES_HOST}:${DB_POSTGRES_PORT}"
    username: "${DB_POSTGRES_USER}"
    password: "${DB_POSTGRES_PASSWORD}"
    database: "${DB_POSTGRES_DATABASE}"
    sampling:
      interval: 1s
      buffer_size: 10000
      retention_duration: 1h
    metrics_enabled:
      - active_sessions
      - wait_events
      - blocked_sessions
      - long_running_queries

  # Host metrics
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      disk:
        metrics:
          system.disk.io:
            enabled: true
      network:
        metrics:
          system.network.io:
            enabled: true

  # SQL Query receiver for custom queries
  sqlquery:
    driver: postgres
    datasource: "host=${DB_POSTGRES_HOST} port=${DB_POSTGRES_PORT} user=${DB_POSTGRES_USER} password=${DB_POSTGRES_PASSWORD} dbname=${DB_POSTGRES_DATABASE} sslmode=disable"
    collection_interval: 60s
    queries:
      - sql: |
          SELECT 
            state,
            COUNT(*) as connection_count
          FROM pg_stat_activity
          WHERE pid != pg_backend_pid()
          GROUP BY state
        metrics:
          - metric_name: postgresql.connections.by_state
            value_column: connection_count
            attribute_columns:
              - state

processors:
  # 1. Memory limiter (always first - protects collector)
  memory_limiter:
    check_interval: 1s
    limit_mib: 2048
    spike_limit_mib: 512
    limit_percentage: 0
    spike_limit_percentage: 0

  # 2. Resource processor (early - adds resource attributes)
  resource:
    attributes:
      - key: service.name
        value: "${SERVICE_NAME}"
        action: upsert
      - key: environment
        value: "${ENVIRONMENT}"
        action: upsert
      - key: db.system
        value: postgresql
        action: insert
      - key: db.deployment.type
        value: "${DB_DEPLOYMENT_TYPE:-standalone}"
        action: insert

  # 3. Circuit breaker (early protection)
  circuitbreaker:
    enabled: true
    failure_threshold: 5
    success_threshold: 2
    timeout: 30s
    max_requests: 100
    interval: 60s
    database_specific:
      enabled: true
      databases:
        - name: "${DB_POSTGRES_DATABASE}"
          failure_threshold: 3

  # 4. Plan attribute extractor (data enrichment)
  planattributeextractor:
    enabled: true
    plan_cache_size: 1000
    extract_fields:
      - plan_cost
      - plan_rows
      - plan_width
      - node_types
      - join_types
    add_query_hash: true

  # 5. Query correlator (correlation)
  querycorrelator:
    enabled: true
    correlation_window: 5m
    max_queries_tracked: 10000
    correlate_by:
      - session_id
      - transaction_id
      - user_name

  # 6. Transform processor (metric transformation)
  transform:
    metric_statements:
      - context: datapoint
        statements:
          - set(attributes["db.name"], attributes["database_name"]) where attributes["database_name"] != nil
          - delete_key(attributes, "database_name") where attributes["db.name"] != nil

  # 7. Attributes processor (cleanup)
  attributes:
    actions:
      - key: password
        action: delete
      - key: db.statement
        action: hash
      - key: user_query
        action: hash
      - pattern: ^internal.*
        action: delete

  # 8. OHI transform processor (for dashboard compatibility)
  ohitransform:
    enable_metric_to_event: true
    preserve_original_metrics: true
    transform_rules:
      - source_metric: "db.ash.active_sessions"
        target_event: "PostgresSlowQueries"
        mappings:
          db.querylens.queryid: "query_id"
          db.query.execution_time_mean: "avg_elapsed_time_ms"
          db.query.calls: "execution_count"
          db.name: "database_name"
      - source_metric: "db.ash.wait_events"
        target_event: "PostgresWaitEvents"
        mappings:
          wait_event_name: "wait_event_name"
          wait_time_ms: "total_wait_time_ms"
          db.name: "database_name"
      - source_metric: "db.ash.blocked_sessions"
        target_event: "PostgresBlockingSessions"
        mappings:
          blocked_pid: "blocked_pid"
          blocking_pid: "blocking_pid"
          db.name: "database_name"

  # 9. Verification processor (data validation)
  verification:
    enabled: true
    pii_detection:
      enabled: true
      patterns:
        - ssn
        - credit_card
        - email
        - phone
    quality_checks:
      enabled: true
      max_cardinality: 10000
      max_attribute_length: 1024

  # 10. Adaptive sampler (intelligent sampling)
  adaptive_sampler:
    enabled: true
    sampling_rules:
      - name: "critical_metrics"
        pattern: "postgresql\\.(commits|rollbacks|deadlocks)"
        sampling_rate: 1.0
      - name: "query_performance"
        pattern: "db\\.query\\..*"
        sampling_rate: 0.1
      - name: "ash_data"
        pattern: "db\\.ash\\..*"
        sampling_rate: 0.05
      - name: "table_metrics"
        pattern: "postgresql\\.table\\..*"
        sampling_rate: 0.01
    max_metrics_per_minute: 100000

  # 11. Cost control (budget enforcement)
  costcontrol:
    enabled: true
    nr_account_id: "${NEW_RELIC_ACCOUNT_ID}"
    nr_api_key: "${NEW_RELIC_API_KEY}"
    limits:
      max_metrics_per_minute: 5000000
      max_metric_cardinality: 100000
      daily_budget_gb: 100
    enforcement_actions:
      - drop_attributes
      - increase_sampling
      - drop_metrics

  # 12. Cumulative to delta (metric conversion)
  cumulativetodelta:
    include:
      match_type: regexp
      metrics:
        - postgresql\.commits
        - postgresql\.rollbacks
        - postgresql\.blocks\..*
        - postgresql\.rows\..*

  # 13. NR error monitor (export monitoring)
  nrerrormonitor:
    enabled: true
    monitor_interval: 30s
    error_threshold: 100
    alert_on_errors: true

  # 14. Batch processor (final batching)
  batch:
    send_batch_size: 8192
    timeout: 10s
    send_batch_max_size: 16384

exporters:
  # OTLP exporter to New Relic
  otlphttp:
    endpoint: "${NEW_RELIC_OTLP_ENDPOINT}"
    headers:
      api-key: "${NEW_RELIC_LICENSE_KEY}"
    compression: gzip
    timeout: 30s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 5000

  # Prometheus exporter for local monitoring
  prometheus:
    endpoint: "0.0.0.0:9090"
    namespace: database_intelligence
    const_labels:
      environment: "${ENVIRONMENT}"
      service: "${SERVICE_NAME}"
    metric_expiration: 5m
    enable_open_metrics: true

  # Debug exporter (disabled by default)
  debug:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 100

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133
    path: "/health"
    check_collector_pipeline:
      enabled: true
      interval: 5s
      exporter_failure_threshold: 5

  # Performance profiler
  pprof:
    endpoint: 0.0.0.0:1777
    block_profile_fraction: 0
    mutex_profile_fraction: 0

  # PostgreSQL query lens extension
  postgresqlquery:
    endpoint: "${DB_POSTGRES_HOST}:${DB_POSTGRES_PORT}"
    username: "${DB_POSTGRES_USER}"
    password: "${DB_POSTGRES_PASSWORD}"
    database: "${DB_POSTGRES_DATABASE}"

service:
  # Enable extensions
  extensions: 
    - health_check
    - pprof
    - postgresqlquery
  
  # Pipeline configuration with correct processor ordering
  pipelines:
    metrics/enhanced:
      receivers:
        - postgresql
        - enhancedsql
        - ash
        - hostmetrics
        - sqlquery
      processors:
        # Correct processor ordering for optimal performance and functionality
        - memory_limiter          # 1. Protection (always first)
        - resource               # 2. Resource attribution (early)
        - circuitbreaker        # 3. Early protection
        - planattributeextractor # 4. Data enrichment
        - querycorrelator       # 5. Correlation
        - transform             # 6. Metric transformation
        - attributes            # 7. Attribute cleanup
        - ohitransform          # 8. OHI compatibility
        - verification          # 9. Data validation
        - adaptive_sampler      # 10. Intelligent sampling
        - costcontrol          # 11. Budget enforcement
        - cumulativetodelta    # 12. Metric conversion
        - nrerrormonitor       # 13. Export monitoring
        - batch                # 14. Final batching (always last)
      exporters:
        - otlphttp
        - prometheus
        # - debug  # Uncomment for troubleshooting

  # Telemetry configuration
  telemetry:
    logs:
      level: info
      encoding: json
      output_paths:
        - stdout
        - /var/log/otelcol/collector.log
      error_output_paths:
        - stderr
        - /var/log/otelcol/collector-error.log
    
    metrics:
      level: detailed
      address: 0.0.0.0:8888