# Config-Only Mode - Working Configuration
# This configuration uses only standard OpenTelemetry components
# Works with standard otel/opentelemetry-collector-contrib image

# Environment variables required:
# - DB_POSTGRES_HOST: PostgreSQL host
# - DB_POSTGRES_PORT: PostgreSQL port (default: 5432)
# - DB_POSTGRES_USER: PostgreSQL username
# - DB_POSTGRES_PASSWORD: PostgreSQL password
# - DB_POSTGRES_DATABASE: PostgreSQL database name
# - NEW_RELIC_OTLP_ENDPOINT: New Relic OTLP endpoint (default: https://otlp.nr-data.net:4318)
# - NEW_RELIC_LICENSE_KEY: New Relic license key
# - SERVICE_NAME: Service identifier (e.g., postgresql-prod-01)
# - ENVIRONMENT: Environment name (dev/staging/prod)

receivers:
  # PostgreSQL receiver for database metrics
  postgresql:
    endpoint: "${DB_POSTGRES_HOST}:${DB_POSTGRES_PORT}"
    username: "${DB_POSTGRES_USER}"
    password: "${DB_POSTGRES_PASSWORD}"
    databases:
      - "${DB_POSTGRES_DATABASE}"
    collection_interval: 30s
    transport: tcp
    tls:
      insecure: true  # Set to false in production
    initial_delay: 1s

  # Host metrics receiver
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      disk:
        metrics:
          system.disk.io:
            enabled: true
          system.disk.io_time:
            enabled: true
          system.disk.operations:
            enabled: true
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true
      network:
        metrics:
          system.network.io:
            enabled: true
          system.network.connections:
            enabled: true
      load:
        metrics:
          system.cpu.load_average.1m:
            enabled: true
          system.cpu.load_average.5m:
            enabled: true
          system.cpu.load_average.15m:
            enabled: true

  # SQL Query receiver for custom queries
  sqlquery:
    driver: postgres
    datasource: "host=${DB_POSTGRES_HOST} port=${DB_POSTGRES_PORT} user=${DB_POSTGRES_USER} password=${DB_POSTGRES_PASSWORD} dbname=${DB_POSTGRES_DATABASE} sslmode=disable"
    collection_interval: 60s
    queries:
      # Connection metrics by state
      - sql: |
          SELECT 
            COALESCE(state, 'idle') as state,
            COUNT(*) as connection_count
          FROM pg_stat_activity
          WHERE pid != pg_backend_pid()
          GROUP BY state
        metrics:
          - metric_name: postgresql.connections.by_state
            value_column: connection_count
            value_type: int
            attribute_columns:
              - state

      # Long running queries
      - sql: |
          SELECT 
            COUNT(*) as count
          FROM pg_stat_activity
          WHERE state = 'active'
            AND query_start < NOW() - INTERVAL '5 minutes'
            AND query NOT LIKE 'autovacuum:%'
        metrics:
          - metric_name: postgresql.queries.long_running.count
            value_column: count
            value_type: int

      # Database size metrics
      - sql: |
          SELECT 
            datname as database,
            pg_database_size(datname) as size_bytes
          FROM pg_database
          WHERE datallowconn = true
        metrics:
          - metric_name: postgresql.database.size.bytes
            value_column: size_bytes
            value_type: int
            attribute_columns:
              - database

      # Table bloat estimation
      - sql: |
          WITH constants AS (
            SELECT current_setting('block_size')::numeric AS bs, 23 AS hdr, 4 AS ma
          ),
          bloat_info AS (
            SELECT
              schemaname,
              tablename,
              cc.relpages,
              bs,
              CEIL((cc.reltuples*((datahdr+ma-
                (CASE WHEN datahdr%ma=0 THEN ma ELSE datahdr%ma END))+nullhdr2+4))/(bs-20::float)) AS otta
            FROM (
              SELECT
                schemaname,
                tablename,
                hdr,
                ma,
                bs,
                SUM((1-null_frac)*avg_width) AS nullhdr2,
                MAX(hdr+1+(rint((null_frac*natts)::float/8))) AS datahdr
              FROM (
                SELECT
                  schemaname,
                  tablename,
                  hdr,
                  ma,
                  bs,
                  null_frac,
                  avg_width,
                  natts
                FROM pg_stats s2
                CROSS JOIN constants
                WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
              ) AS foo
              GROUP BY schemaname, tablename, hdr, ma, bs
            ) AS rs
            JOIN pg_class cc ON cc.relname = rs.tablename
            JOIN pg_namespace nn ON cc.relnamespace = nn.oid AND nn.nspname = rs.schemaname
          )
          SELECT
            schemaname,
            tablename,
            ROUND((CASE WHEN otta=0 THEN 0.0 ELSE relpages/otta::numeric END)::numeric,1) AS bloat_ratio,
            CASE WHEN relpages < otta THEN 0 ELSE (bs*(relpages-otta))::bigint END AS bloat_bytes
          FROM bloat_info
          ORDER BY bloat_bytes DESC
          LIMIT 10
        metrics:
          - metric_name: postgresql.table.bloat.ratio
            value_column: bloat_ratio
            value_type: double
            attribute_columns:
              - schemaname
              - tablename
          - metric_name: postgresql.table.bloat.bytes
            value_column: bloat_bytes
            value_type: int
            attribute_columns:
              - schemaname
              - tablename

processors:
  # Memory limiter to prevent OOM
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128

  # Resource processor for standard attributes
  resource:
    attributes:
      - key: service.name
        value: "${SERVICE_NAME}"
        action: upsert
      - key: deployment.environment
        value: "${ENVIRONMENT}"
        action: upsert
      - key: db.system
        value: postgresql
        action: insert
      - key: cloud.provider
        value: "${CLOUD_PROVIDER}"
        action: insert
        from_attribute: cloud_provider
      - key: cloud.region
        value: "${CLOUD_REGION}"
        action: insert
        from_attribute: cloud_region

  # Transform processor for metric adjustments
  transform:
    metric_statements:
      # Convert bytes to MB for easier reading
      - context: metric
        statements:
          - set(unit, "By") where name == "postgresql.database.size.bytes"
          - set(unit, "By") where name == "postgresql.table.bloat.bytes"
      # Calculate cache hit ratio
      - context: metric
        statements:
          - set(name, "postgresql.cache.hit_ratio") where name == "postgresql.blocks.hit"
          - set(unit, "%") where name == "postgresql.cache.hit_ratio"

  # Attributes processor for cleanup and enrichment
  attributes:
    actions:
      # Remove sensitive information
      - key: password
        action: delete
      - key: postgresql.query
        action: hash
      # Standardize attribute names
      - key: db.name
        from_attribute: database
        action: insert
      - key: db.postgresql.version
        from_attribute: postgresql.version
        action: insert
      # Remove internal attributes
      - pattern: ^otel\..*
        action: delete

  # Filter processor to exclude system databases
  filter:
    metrics:
      exclude:
        match_type: strict
        metric_names:
          - postgresql.database.size.bytes
        attributes:
          - key: database
            value: template0
          - key: database
            value: template1

  # Cumulative to delta for counter metrics
  cumulativetodelta:
    include:
      match_type: regexp
      metrics:
        - postgresql\.commits
        - postgresql\.rollbacks
        - postgresql\.blocks\.hit
        - postgresql\.blocks\.read
        - postgresql\.rows\.deleted
        - postgresql\.rows\.fetched
        - postgresql\.rows\.inserted
        - postgresql\.rows\.updated

  # Batch processor for efficient sending
  batch:
    send_batch_size: 8192
    timeout: 10s
    send_batch_max_size: 16384

exporters:
  # OTLP HTTP exporter to New Relic
  otlphttp:
    endpoint: "${NEW_RELIC_OTLP_ENDPOINT}"
    headers:
      api-key: "${NEW_RELIC_LICENSE_KEY}"
    compression: gzip
    timeout: 30s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 5000
      storage: file_storage

  # Prometheus exporter for local scraping
  prometheus:
    endpoint: "0.0.0.0:9090"
    namespace: database
    const_labels:
      environment: "${ENVIRONMENT}"
      service: "${SERVICE_NAME}"
    resource_to_telemetry_conversion:
      enabled: true
    enable_open_metrics: true

  # Debug exporter for troubleshooting
  debug:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 100

extensions:
  # Health check
  health_check:
    endpoint: 0.0.0.0:13133
    path: "/health"
    check_collector_pipeline:
      enabled: true
      interval: 5s
      exporter_failure_threshold: 5

  # Performance profiler
  pprof:
    endpoint: 0.0.0.0:1777
    block_profile_fraction: 0
    mutex_profile_fraction: 0

  # File storage for queue persistence
  file_storage:
    directory: /var/lib/otelcol/file_storage
    timeout: 10s
    compaction:
      on_start: true
      directory: /var/lib/otelcol/file_storage/compaction
      max_transaction_size: 65536

service:
  extensions: [health_check, pprof, file_storage]
  
  pipelines:
    metrics:
      receivers: [postgresql, hostmetrics, sqlquery]
      processors: [memory_limiter, resource, transform, attributes, filter, cumulativetodelta, batch]
      exporters: [otlphttp, prometheus]

  telemetry:
    logs:
      level: info
      encoding: json
      output_paths: [stdout]
      error_output_paths: [stderr]
    
    metrics:
      level: detailed
      address: 0.0.0.0:8888