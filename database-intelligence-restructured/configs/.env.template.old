# OpenTelemetry Collector Environment Variables Template
# Copy this file to .env and fill in your actual values
# DO NOT commit .env files to version control

# ===== SERVICE CONFIGURATION =====
# Basic service identification
SERVICE_NAME=database-intelligence-collector
SERVICE_VERSION=2.0.0
DEPLOYMENT_ENVIRONMENT=development  # development, staging, production
HOSTNAME=${HOSTNAME}

# ===== DATABASE CONNECTIONS =====
# PostgreSQL Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=postgres
POSTGRES_SSLMODE=disable  # disable, require, verify-ca, verify-full
POSTGRES_TLS_INSECURE=true
POSTGRES_CA_FILE=/path/to/ca.crt
POSTGRES_CERT_FILE=/path/to/client.crt
POSTGRES_KEY_FILE=/path/to/client.key

# MySQL Configuration
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=root
MYSQL_PASSWORD=mysql
MYSQL_DB=mysql
MYSQL_CA_FILE=/path/to/mysql-ca.crt

# ===== COLLECTION INTERVALS =====
# How often to collect metrics (format: 10s, 1m, 5m)
POSTGRES_COLLECTION_INTERVAL=60s
MYSQL_COLLECTION_INTERVAL=60s
POSTGRES_QUERY_INTERVAL=300s
MYSQL_QUERY_INTERVAL=300s
ENHANCED_SQL_INTERVAL=60s

# ===== OTLP CONFIGURATION =====
# OTLP Receiver Settings
OTLP_GRPC_ENDPOINT=0.0.0.0:4317
OTLP_HTTP_ENDPOINT=0.0.0.0:4318
OTLP_MAX_RECV_MSG_SIZE=32
OTLP_MAX_REQUEST_BODY_SIZE=32

# OTLP Exporter Settings
OTLP_ENDPOINT=https://otlp.nr-data.net
NEW_RELIC_LICENSE_KEY=YOUR_LICENSE_KEY_HERE
OTLP_TIMEOUT=30s
OTLP_RETRY_INITIAL_INTERVAL=5s
OTLP_RETRY_MAX_INTERVAL=30s
OTLP_RETRY_MAX_ELAPSED_TIME=300s
OTLP_QUEUE_CONSUMERS=10
OTLP_QUEUE_SIZE=5000

# Environment-specific endpoints
STAGING_OTLP_ENDPOINT=https://staging-otlp.nr-data.net
STAGING_API_KEY=YOUR_STAGING_KEY_HERE
PROD_OTLP_ENDPOINT=https://otlp.nr-data.net
PROD_OTLP_GRPC_ENDPOINT=https://otlp.nr-data.net:4317

# ===== NEW RELIC CONFIGURATION =====
NEW_RELIC_API_KEY=YOUR_API_KEY_HERE
NEW_RELIC_ACCOUNT_ID=YOUR_ACCOUNT_ID_HERE
NEW_RELIC_INGEST_KEY=YOUR_INGEST_KEY_HERE

# ===== RESOURCE LIMITS =====
# Memory limiter settings (in MiB)
MEMORY_LIMIT_MIB=512
MEMORY_SPIKE_LIMIT_MIB=128
MEMORY_CHECK_INTERVAL=1s
MEMORY_BALLAST_SIZE_MIB=64

# ===== BATCH PROCESSING =====
BATCH_TIMEOUT=1s
BATCH_SIZE=1024
BATCH_MAX_SIZE=2048

# ===== SAMPLING CONFIGURATION =====
# Adaptive sampling settings
ADAPTIVE_SAMPLING_PERCENTAGE=10
MAX_TRACES_PER_SECOND=100
SAMPLED_CACHE_SIZE=100000
NONSAMPLED_CACHE_SIZE=100000
SELECT_SAMPLING_PERCENTAGE=5
DML_SAMPLING_PERCENTAGE=50
AUDIT_SAMPLING_PERCENTAGE=1

# ===== CIRCUIT BREAKER =====
CIRCUIT_BREAKER_MAX_FAILURES=5
CIRCUIT_BREAKER_FAILURE_THRESHOLD=50
CIRCUIT_BREAKER_TIMEOUT=30s
CIRCUIT_BREAKER_RECOVERY_TIMEOUT=60s
PER_DATABASE_CIRCUIT=true
HEALTH_CHECK_INTERVAL=10s

# ===== COST CONTROL =====
DAILY_BUDGET_USD=100
MONTHLY_BUDGET_USD=3000
COST_PER_GB=0.25
COST_PER_MILLION_EVENTS=2.00
COST_ALERT_THRESHOLD=80
COST_ENFORCEMENT_ENABLED=false

# ===== PLAN ANALYSIS =====
ENABLE_PLAN_COLLECTION=false
PLAN_CACHE_SIZE=1000
PLAN_CACHE_ENABLED=true
PLAN_CACHE_MAX_SIZE=10000
PLAN_CACHE_TTL=3600s
ENABLE_ANONYMIZATION=true
ENABLE_PLAN_ANALYSIS=true
MAX_QUERY_LENGTH=4096

# ===== DATA VERIFICATION =====
ENABLE_PII_DETECTION=true
ENABLE_DATA_VALIDATION=true
MAX_FIELD_LENGTH=1000
VERIFICATION_SAMPLE_RATE=0.1

# ===== CORRELATION =====
CORRELATION_WINDOW=30s
MAX_CORRELATIONS=1000
ENABLE_TRACE_CORRELATION=true

# ===== MONITORING ENDPOINTS =====
# Prometheus exporter
PROMETHEUS_ENDPOINT=0.0.0.0:8889
PROMETHEUS_NAMESPACE=database-intelligence
PROMETHEUS_METRIC_EXPIRATION=10m
PROMETHEUS_ENABLE_OPEN_METRICS=false

# Health check
HEALTH_CHECK_ENDPOINT=0.0.0.0:13133
HEALTH_CHECK_PATH=/
HEALTH_CHECK_PIPELINE_ENABLED=true
HEALTH_CHECK_INTERVAL=5m
HEALTH_CHECK_EXPORTER_FAILURE_THRESHOLD=5

# Performance profiling
PPROF_ENDPOINT=0.0.0.0:1777
PPROF_BLOCK_PROFILE_FRACTION=0
PPROF_MUTEX_PROFILE_FRACTION=0
PPROF_SAVE_TO_FILE=

# zPages debugging
ZPAGES_ENDPOINT=0.0.0.0:55679

# ===== LOGGING CONFIGURATION =====
LOG_LEVEL=info  # debug, info, warn, error
LOG_DEVELOPMENT=false
LOG_ENCODING=json  # json, console
LOGGING_EXPORTER_LEVEL=info
LOGGING_SAMPLING_INITIAL=2
LOGGING_SAMPLING_THEREAFTER=500
DEBUG_VERBOSITY=normal  # basic, normal, detailed
DEBUG_SAMPLING_INITIAL=5
DEBUG_SAMPLING_THEREAFTER=200

# ===== TELEMETRY =====
TELEMETRY_METRICS_LEVEL=basic  # none, basic, normal, detailed
TELEMETRY_METRICS_ADDRESS=0.0.0.0:8888

# ===== FILE STORAGE =====
FILE_STORAGE_DIRECTORY=/tmp/otel-storage
FILE_STORAGE_TIMEOUT=1s
FILE_STORAGE_COMPACTION_DIRECTORY=/tmp/otel-storage-compaction
FILE_STORAGE_COMPACTION_ON_START=false
FILE_STORAGE_COMPACTION_ON_REBOUND=true
FILE_STORAGE_REBOUND_THRESHOLD_MIB=100
FILE_STORAGE_REBOUND_TRIGGER_MIB=150

# ===== FILE EXPORTER (Development) =====
FILE_EXPORTER_PATH=/tmp/otel-data.json
FILE_ROTATION_MAX_MB=100
FILE_ROTATION_MAX_DAYS=7
FILE_ROTATION_MAX_BACKUPS=3
FILE_EXPORTER_FORMAT=json

# ===== AUTHENTICATION =====
# Basic auth
BASIC_AUTH_HTPASSWD_FILE=/etc/otelcol/auth/.htpasswd
BASIC_AUTH_INLINE=

# Bearer token
BEARER_TOKEN=
BEARER_TOKEN_FILE=

# OAuth2
OAUTH2_CLIENT_ID=
OAUTH2_CLIENT_SECRET=
OAUTH2_TOKEN_URL=
OAUTH2_SCOPE=read
OAUTH2_AUDIENCE=

# ===== CUSTOM HEADERS =====
HEADERS_ACTION=upsert
HEADERS_KEY=X-Custom-Header
HEADERS_VALUE=database-intelligence

# ===== GATEWAY CONFIGURATION =====
GATEWAY_ENDPOINT=http://gateway-collector:4318
GATEWAY_TOKEN=
GATEWAY_TIMEOUT=10s
GATEWAY_RETRY_INITIAL_INTERVAL=1s
GATEWAY_RETRY_MAX_INTERVAL=5s
GATEWAY_RETRY_MAX_ELAPSED_TIME=30s

# ===== ADDITIONAL EXPORTERS =====
# Jaeger
JAEGER_ENDPOINT=http://localhost:14268/api/traces
JAEGER_TIMEOUT=5s
JAEGER_RETRY_INITIAL_INTERVAL=5s
JAEGER_RETRY_MAX_INTERVAL=30s
JAEGER_RETRY_MAX_ELAPSED_TIME=120s

# Kafka
KAFKA_BROKER_1=localhost:9092
KAFKA_TOPIC=otel-database-metrics
KAFKA_ENCODING=otlp_proto
KAFKA_PARTITION_KEY=service.name
KAFKA_TIMEOUT=5s
KAFKA_MAX_RETRIES=3
KAFKA_RETRY_BACKOFF=100ms

# ===== CONTAINER DISCOVERY =====
# Docker observer
DOCKER_OBSERVER_ENDPOINT=unix:///var/run/docker.sock
DOCKER_OBSERVER_TIMEOUT=5s
DOCKER_OBSERVER_EXCLUDED_IMAGE_1=otel/opentelemetry-collector*
DOCKER_OBSERVER_USE_HOSTNAME=false
DOCKER_OBSERVER_USE_HOST_BINDINGS=false

# Kubernetes observer
K8S_OBSERVER_AUTH_TYPE=serviceAccount
K8S_OBSERVER_NODE=${K8S_NODE_NAME}
K8S_OBSERVER_OBSERVE_PODS=true
K8S_OBSERVER_OBSERVE_NODES=false

# ===== HTTP FORWARDER =====
HTTP_FORWARDER_INGRESS_ENDPOINT=0.0.0.0:6060
HTTP_FORWARDER_EGRESS_ENDPOINT=http://backend:8080
HTTP_FORWARDER_EGRESS_TIMEOUT=5s

# ===== ERROR MONITORING =====
NR_ERROR_THRESHOLD=10
NR_VALIDATION_INTERVAL=300s
ENABLE_NR_VALIDATION=true