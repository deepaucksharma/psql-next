# Database Intelligence Collector - Test Configuration
# For E2E validation testing with PostgreSQL

extensions:
  health_check:
    endpoint: 0.0.0.0:13133
    path: /health
  
  zpages:
    endpoint: 0.0.0.0:55679

receivers:
  # PostgreSQL metrics using postgresql receiver
  postgresql:
    endpoint: localhost:5432
    username: postgres
    password: pass
    collection_interval: 10s
    tls:
      insecure: true
    databases:
      - postgres
    
  # Query performance metrics using sqlquery receiver
  sqlquery/postgresql_queries:
    driver: postgres
    datasource: postgres://postgres:pass@localhost:5432/postgres?sslmode=disable
    collection_interval: 15s
    queries:
      # Slow queries - maps to PostgresSlowQueries
      - sql: |
          SELECT 
            queryid::text as query_id,
            query as query_text,
            COALESCE((SELECT datname FROM pg_database WHERE oid = dbid), 'unknown') as database_name,
            calls as execution_count,
            mean_exec_time as avg_elapsed_time_ms,
            total_exec_time as total_time_ms,
            rows as total_rows,
            shared_blks_read as avg_disk_reads,
            shared_blks_written as avg_disk_writes,
            'SELECT' as statement_type
          FROM pg_stat_statements
          WHERE query NOT LIKE '%pg_%'
            AND mean_exec_time > 100  -- Lower threshold for testing
          ORDER BY mean_exec_time DESC
          LIMIT 100
        metrics:
          - metric_name: postgres.slow_queries
            value_column: avg_elapsed_time_ms
            attribute_columns: [query_id, query_text, database_name, execution_count, avg_disk_reads, avg_disk_writes, statement_type]
            value_type: double
            
      # Wait events - maps to PostgresWaitEvents
      - sql: |
          SELECT 
            wait_event as wait_event_name,
            wait_event_type as wait_category,
            count(*) as total_wait_time_ms,
            datname as database_name
          FROM pg_stat_activity
          WHERE wait_event IS NOT NULL
          GROUP BY wait_event, wait_event_type, datname
        metrics:
          - metric_name: postgres.wait_events
            value_column: total_wait_time_ms
            attribute_columns: [wait_event_name, wait_category, database_name]
            value_type: double
            
      # Blocking sessions - maps to PostgresBlockingSessions
      - sql: |
          SELECT
            blocked.pid as blocked_pid,
            blocked.query as blocked_query,
            blocking.pid as blocking_pid,
            blocking.query as blocking_query,
            blocked.datname as database_name
          FROM pg_stat_activity blocked
          JOIN pg_stat_activity blocking 
            ON blocking.pid = ANY(pg_blocking_pids(blocked.pid))
          WHERE blocked.wait_event IS NOT NULL
        metrics:
          - metric_name: postgres.blocking_sessions
            value_column: blocked_pid
            attribute_columns: [blocked_query, blocking_pid, blocking_query, database_name]
            value_type: int

processors:
  # Add db.system attribute
  attributes:
    actions:
      - key: db.system
        value: postgresql
        action: insert
        
  # Add resource attributes
  resource:
    attributes:
      - key: environment
        value: e2e-test
        action: upsert
      - key: service.name
        value: database-intelligence
        action: upsert
        
  # Memory limiter
  memory_limiter:
    check_interval: 1s
    limit_percentage: 75
    spike_limit_percentage: 30
    
  # Batch processor
  batch:
    timeout: 10s
    send_batch_size: 1000

exporters:
  # New Relic exporter
  otlp:
    endpoint: https://otlp.nr-data.net:4317
    headers:
      api-key: ${NEW_RELIC_LICENSE_KEY}
    compression: gzip
    
  # Debug exporter for troubleshooting
  debug:
    verbosity: detailed
    sampling_initial: 10
    sampling_thereafter: 100

service:
  extensions: [health_check, zpages]
  
  pipelines:
    metrics:
      receivers: [postgresql, sqlquery/postgresql_queries]
      processors: [attributes, resource, memory_limiter, batch]
      exporters: [otlp, debug]
      
  telemetry:
    logs:
      level: info
      initial_fields:
        service: database-intelligence-collector